Installation stuff
===================

python3 -m pip install pyautogui

sudo apt-get install scrot

sudo apt-get install python3-tk

sudo apt-get install python3-dev

pip install python-xlib

(for mss.tool fast screengrab )
pip install mss


How to run the behavior cloning project
=======================================

1. First record the game you want to behavior clone:
---------------------------------------------------
open datacreators/utils/gameplay_recorder.py
edit the folder location in line 34 and also make sure that folder exists in the mentioned location
you can change the mode to find_region to first find the region in the screen to capture 
once you find the region, input those values in find_interesting_region() function
change mode to record and run the code again it will record the gameplay and save it in the name you specified in folder variable
run datacreators/utils/max_diversity_sampler.py

2. Train variational encoding model :
-------------------------------------
go to examples/variational_encoders/main.py and focus on the variable data_trainset in line 109, there change the root variable to the exact location where the sampled gameplay images are placed
sampled because it doesnt need to contain all the images in exact sequence, just relevant and distinct images covering all instances of the game
then run the main_b.py (beta vae model)
After around 500 epochs you can check in the results folder generated_sample<i>.png and reconstructed_sample<i>.png will start to have meaningful images
The trained weights would also be saved as pt files

you can test how well the vae trained by also running test_b.py

3. Train the latent gpt model :
-------------------------------
Now we will train gpt model on latent representations of the game image
go to examples/behavior_clone/train_latent_gpt.py and edit the parameters of BigramLanguageModel() in line 109, also make sure the model definition is same in test_latent_gpt.py in the same folder
also check the get_latents() function in both of the codes to vary the encoded representation to your liking (add biases if you want)

also make sure you are loading the proper vae weights for state_encoder in line 133

run train_latent_gpt.py and after sufficient training it should produce some intelligent behavior
You can now test the entire behavior cloning by opening the website for the game - https://www.crazygames.com/game/crazy-assassin
and run test_latent_gpt.py 

in test_latent_gpt.py you can change the agent perception lag parameter in line 274 by changing the value inside time.sleep() currently the model runs 1 inference in 0.02 seconds and that is also 
the frame interval in which the training data is collected (roughly)

main_gan.py and main_simple.py were 2 variants I had tried to use timesformer to directly learn the actions without latent encoding and they didnt work well


(alternate)
If you want to train directly on images cnn encoding + gpt and dont use variational encoders
run train_vis_gpt.py to train
and
test_vis_gpt2.py to test


(major change in training style, improves training)
in the BigramLanguageModel and visgpt model definitions inside models/gpt.py class a new technique has been added where self.loss_type= "mse" ... it is enabled by default
what is does is convert target to one hot encoded vectors 
and exactly at the index locations where target is 1, converts the gpt model output to 1 and then uses mse loss between gpt output and modified one hot encoded 


Current challenge which affects the performance:
===============================================

0. try larger latent size and attempt to generate higher res 128x128 reconstructions, somehow the small features are lost.. try to get them

Introduce additional input features to gpt based on object/template detection of dynamic moving objects. vae reconstructions generally ignores them or makes them blurry

1.	Find a way to train higher resolution beta vae models with a larger latent dimension size that captures more details